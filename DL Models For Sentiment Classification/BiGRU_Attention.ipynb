{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchtext.legacy.data import Field\n",
    "\n",
    "import model\n",
    "import train\n",
    "import dataset\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "args = config.args_initialization()\n",
    "\n",
    "args.save_dir = \"D:/python/pyprojects/NLP/Text Classification/model/BiGRU_Attention\"\n",
    "\n",
    "args.epochs = 20\n",
    "args.static = True\n",
    "\n",
    "args.batch_size = 32\n",
    "args.hidden_size = 50\n",
    "args.layers_num = 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loding data successfully\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "text_field = Field()\n",
    "label_field = Field(sequential=False,use_vocab=False,unk_token=None)\n",
    "train_iter, dev_iter = dataset.load_dataset(text_field, label_field, args, device=-1, repeat=False, shuffle=True)\n",
    "print(\"Loding data successfully\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:BiGRU_Attention\n",
      "Parameters:\n",
      "\tBATCH_SIZE=32\n",
      "\tCLASS_NUM=2\n",
      "\tCUDA=False\n",
      "\tDEVICE=-1\n",
      "\tDROPOUT=0.5\n",
      "\tEMBEDDING_DIM=300\n",
      "\tEPOCHS=20\n",
      "\tFILTER_NUM=100\n",
      "\tFILTER_SIZES=[1, 3, 5]\n",
      "\tHIDDEN_SIZE=50\n",
      "\tLAYERS_NUM=3\n",
      "\tLR=0.001\n",
      "\tMULTICHANNEL=False\n",
      "\tNON_STATIC=False\n",
      "\tPRETRAINED_NAME=sgns.wiki.word\n",
      "\tPRETRAINED_PATH=D:/python/pyprojects/NLP/Text Classification/data\n",
      "\tSAVE_DIR=D:/python/pyprojects/NLP/Text Classification/model/BiGRU_Attention\n",
      "\tSTATIC=True\n",
      "\tVOCABULARY_SIZE=7877\n",
      "Epoch 0 Steps: 339/339 - loss: 0.140017  acc: 100.0000%(11/11)\n",
      "\n",
      "Evaluating Epoch 0\n",
      "Evaluation - loss: 0.321082  f1: 0.6191  acc: 85.9993%\n",
      "Saving the best model, epoch : 0 f1 : 0.6191 acc: 85.9993%\n",
      "-----------------------------------------------------------\n",
      "Epoch 1 Steps: 339/339 - loss: 0.131160  acc: 100.0000%(11/11)\n",
      "\n",
      "Evaluating Epoch 1\n",
      "Evaluation - loss: 0.284466  f1: 0.7024  acc: 87.8833%\n",
      "Saving the best model, epoch : 1 f1 : 0.7024 acc: 87.8833%\n",
      "-----------------------------------------------------------\n",
      "Epoch 2 Steps: 339/339 - loss: 0.431253  acc: 90.9091%(10/11))\n",
      "\n",
      "Evaluating Epoch 2\n",
      "Evaluation - loss: 0.274761  f1: 0.6974  acc: 88.1049%\n",
      "-----------------------------------------------------------\n",
      "Epoch 3 Steps: 339/339 - loss: 0.055222  acc: 100.0000%(11/11)\n",
      "\n",
      "Evaluating Epoch 3\n",
      "Evaluation - loss: 0.298411  f1: 0.6694  acc: 88.1419%\n",
      "-----------------------------------------------------------\n",
      "Epoch 4 Steps: 339/339 - loss: 0.554095  acc: 63.6364%(7/11)))\n",
      "\n",
      "Evaluating Epoch 4\n",
      "Evaluation - loss: 0.274116  f1: 0.7318  acc: 89.1393%\n",
      "Saving the best model, epoch : 4 f1 : 0.7318 acc: 89.1393%\n",
      "-----------------------------------------------------------\n",
      "Epoch 5 Steps: 339/339 - loss: 0.122580  acc: 100.0000%(11/11)\n",
      "\n",
      "Evaluating Epoch 5\n",
      "Evaluation - loss: 0.299511  f1: 0.7070  acc: 88.7329%\n",
      "-----------------------------------------------------------\n",
      "Epoch 6 Steps: 339/339 - loss: 0.030726  acc: 100.0000%(11/11)\n",
      "\n",
      "Evaluating Epoch 6\n",
      "Evaluation - loss: 0.283327  f1: 0.7453  acc: 89.3979%\n",
      "Saving the best model, epoch : 6 f1 : 0.7453 acc: 89.3979%\n",
      "-----------------------------------------------------------\n",
      "Epoch 7 Steps: 339/339 - loss: 0.047665  acc: 100.0000%(11/11)\n",
      "\n",
      "Evaluating Epoch 7\n",
      "Evaluation - loss: 0.303123  f1: 0.7271  acc: 89.1023%\n",
      "-----------------------------------------------------------\n",
      "Epoch 8 Steps: 339/339 - loss: 0.266417  acc: 81.8182%(9/11)))\n",
      "\n",
      "Evaluating Epoch 8\n",
      "Evaluation - loss: 0.305878  f1: 0.7376  acc: 89.4348%\n",
      "-----------------------------------------------------------\n",
      "Epoch 9 Steps: 339/339 - loss: 0.152395  acc: 90.9091%(10/11))\n",
      "\n",
      "Evaluating Epoch 9\n",
      "Evaluation - loss: 0.370986  f1: 0.7222  acc: 88.9176%\n",
      "-----------------------------------------------------------\n",
      "Epoch 10 Steps: 339/339 - loss: 0.027537  acc: 100.0000%(11/11)\n",
      "\n",
      "Evaluating Epoch 10\n",
      "Evaluation - loss: 0.432111  f1: 0.7165  acc: 89.3609%\n",
      "-----------------------------------------------------------\n",
      "Epoch 11 Steps: 339/339 - loss: 0.465781  acc: 81.8182%(9/11)))\n",
      "\n",
      "Evaluating Epoch 11\n",
      "Evaluation - loss: 0.366935  f1: 0.7346  acc: 88.8437%\n",
      "-----------------------------------------------------------\n",
      "Epoch 12 Steps: 339/339 - loss: 0.147785  acc: 90.9091%(10/11))\n",
      "\n",
      "Evaluating Epoch 12\n",
      "Evaluation - loss: 0.397798  f1: 0.7214  acc: 88.4743%\n",
      "-----------------------------------------------------------\n",
      "Epoch 13 Steps: 339/339 - loss: 0.132883  acc: 90.9091%(10/11))\n",
      "\n",
      "Evaluating Epoch 13\n",
      "Evaluation - loss: 0.476313  f1: 0.6241  acc: 86.7381%\n",
      "-----------------------------------------------------------\n",
      "Epoch 14 Steps: 339/339 - loss: 0.010595  acc: 100.0000%(11/11)\n",
      "\n",
      "Evaluating Epoch 14\n",
      "Evaluation - loss: 0.400726  f1: 0.7422  acc: 88.9915%\n",
      "-----------------------------------------------------------\n",
      "Epoch 15 Steps: 339/339 - loss: 0.167444  acc: 81.8182%(9/11)2)\n",
      "\n",
      "Evaluating Epoch 15\n",
      "Evaluation - loss: 0.443698  f1: 0.7428  acc: 88.5113%\n",
      "-----------------------------------------------------------\n",
      "Epoch 16 Steps: 339/339 - loss: 0.013772  acc: 100.0000%(11/11)\n",
      "\n",
      "Evaluating Epoch 16\n",
      "Evaluation - loss: 0.471302  f1: 0.7235  acc: 88.7329%\n",
      "-----------------------------------------------------------\n",
      "Epoch 17 Steps: 339/339 - loss: 0.013747  acc: 100.0000%(11/11)\n",
      "\n",
      "Evaluating Epoch 17\n",
      "Evaluation - loss: 0.530771  f1: 0.7016  acc: 88.2157%\n",
      "-----------------------------------------------------------\n",
      "Epoch 18 Steps: 339/339 - loss: 0.133638  acc: 90.9091%(10/11))\n",
      "\n",
      "Evaluating Epoch 18\n",
      "Evaluation - loss: 0.535211  f1: 0.7382  acc: 88.7329%\n",
      "-----------------------------------------------------------\n",
      "Epoch 19 Steps: 339/339 - loss: 0.085749  acc: 90.9091%(10/11))\n",
      "\n",
      "Evaluating Epoch 19\n",
      "Evaluation - loss: 0.549794  f1: 0.6909  acc: 87.7355%\n",
      "-----------------------------------------------------------\n",
      "Stop Training. best model: epoch : 6 f1 : 0.7453 acc: 89.3979%\n"
     ]
    }
   ],
   "source": [
    "print(\"Model:BiGRU_Attention\")\n",
    "print(\"Parameters:\")\n",
    "for attr, value in sorted(args.__dict__.items()):\n",
    "    if attr in {'vectors'}:\n",
    "        continue\n",
    "    print('\\t{}={}'.format(attr.upper(), value))\n",
    "\n",
    "bigru_attention = model.BiLSTM_Attention(args)\n",
    "\"\"\"\n",
    "if args.cuda:\n",
    "    torch.cuda.set_device(args.device)\n",
    "    text_cnn = text_cnn.cuda()\n",
    "\"\"\"\n",
    "train.train(train_iter, dev_iter, bigru_attention, args)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}